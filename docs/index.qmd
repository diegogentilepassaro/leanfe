---
title: "leanfe"
subtitle: "Lean, Fast Fixed Effects Regression"
page-layout: full
toc: false
---

::: {.hero-banner}

# üçÉüí® leanfe

### Lean, Fast Fixed Effects Regression for Python and R

High-dimensional fixed effects regression that's **fast** when you need speed, and **memory-efficient** when you're working with data larger than RAM.

::: {.hero-buttons}
[Get Started](get-started.qmd){.btn .btn-primary .btn-lg}
[View on GitHub](https://github.com/diegogentilepassaro/leanfe){.btn .btn-outline-secondary .btn-lg}
:::

:::

## Why leanfe?

::: {.grid}

::: {.g-col-12 .g-col-md-6 .g-col-lg-3}
### ‚ö° Speed
**YOCO + sparse matrices** compress data dramatically and solve much faster. Process millions of observations in seconds.
:::

::: {.g-col-12 .g-col-md-6 .g-col-lg-3}
### üíæ Memory Efficient
**DuckDB backend** processes datasets larger than RAM by streaming from disk. Memory usage stays low regardless of dataset size.
:::

::: {.g-col-12 .g-col-md-6 .g-col-lg-3}
### üîÑ Unified API
**Same syntax** in Python and R. Switch languages without relearning. The API works identically in both.
:::

::: {.g-col-12 .g-col-md-6 .g-col-lg-3}
### üìä Complete Features
**Full econometrics toolkit**: clustered standard errors, factor variables, interactions, IV/2SLS, and more.
:::

:::

## How It Works: Four Key Innovations

leanfe achieves its speed and memory efficiency through four key innovations:

### 1. YOCO Compression (You Only Compress Once)

From [Wong et al. (2021)](https://arxiv.org/abs/2102.11297): many observations share the same regressor values. Instead of processing each row individually, leanfe groups identical rows together:

```
Original: 5M rows with binary treatment √ó 500 firms √ó 100 products
Compressed: ~100K unique combinations (98% reduction!)
```

The math is **lossless** ‚Äî coefficients and standard errors are identical to the full computation, just computed on sufficient statistics (count, sum, sum of squares) per group.

### 2. Sparse FE Dummies

With many FE levels, the design matrix has many dummy columns. But each row only has a few non-zeros (one per FE). Sparse matrices:

- **Store only non-zeros**: Massive memory reduction
- **Skip zero operations**: Much faster matrix multiplication
- **Scale effortlessly**: Adding more FE levels costs almost nothing

### 3. Sparse Cluster Matrix for Clustered SEs

For clustered standard errors, leanfe implements **Section 5.3.1** of Wong et al. (2021):

1. **Within-cluster compression**: Include cluster ID in GROUP BY, so each compressed record belongs to exactly one cluster
2. **Sparse cluster matrix WÃÉ_C**: Maps groups to clusters (G √ó C matrix with one 1 per row)
3. **Vectorized aggregation**: `cluster_scores = WÃÉ_C·µÄ @ (X √ó ·∫Ω‚Å∞)` ‚Äî no loops over clusters!

This makes clustered SEs just as fast as IID/HC1, even with thousands of clusters.

### 4. Smart Strategy Selection

leanfe automatically chooses the optimal computation path based on your data:

- **YOCO compression** for low/medium-cardinality FEs (< 10K levels) ‚Äî fast sparse matrix operations
- **FWL demeaning** for high-cardinality FEs (> 10K levels) ‚Äî avoids huge sparse matrices

Additionally, FEs are automatically sorted by cardinality (low-card first) during demeaning for ~14% faster convergence. You don't need to configure anything ‚Äî leanfe analyzes your data and picks the fastest strategy.

### The Result

| Dataset | Traditional | leanfe | Speedup |
|---------|-------------|--------|---------|
| 1M rows | 0.7s | 0.09s | **7.7x** |
| 5M rows | 3.7s | 0.15s | **24.6x** |

[Learn more about the methodology ‚Üí](benchmarks/methodology.qmd)

## Two Backends: Speed vs Memory

leanfe offers two backends optimized for different scenarios:

::: {.grid}

::: {.g-col-12 .g-col-md-6}
### ‚ö° Polars Backend (Default)

**Best for: Maximum speed when data fits in memory**

- Blazing fast in-memory DataFrame operations
- Lazy evaluation and query optimization
- Zero-copy data sharing with NumPy
- Ideal for interactive analysis and iteration

```python
# Default: fastest option
result = leanfe(data=df, formula="y ~ x | fe", backend="polars")
```
:::

::: {.g-col-12 .g-col-md-6}
### üíæ DuckDB Backend

**Best for: Large datasets that exceed available RAM**

- Streams data from disk (parquet files)
- Constant memory usage regardless of dataset size
- SQL-based query engine with automatic optimization
- Can process 100GB+ datasets on a laptop

```python
# Memory-efficient: handles data larger than RAM
result = leanfe(data="huge_data.parquet", formula="y ~ x | fe", backend="duckdb")
```
:::

:::

| Scenario | Recommended Backend |
|----------|---------------------|
| Data fits in memory, need speed | **Polars** |
| Data larger than RAM | **DuckDB** |
| Reading from parquet files | **DuckDB** |
| Running many regressions on same data | **Polars** |
| Memory-constrained environment | **DuckDB** |

Both backends use YOCO compression + sparse matrices automatically for all SE types.

## Quick Example

Two-way fixed effects regression with clustered standard errors:

::: {.panel-tabset}

### Python (Polars)

```python
from leanfe import leanfe

# Fast in-memory computation (default)
result = leanfe(
    formula="outcome ~ treatment + controls | unit_id + time_id",
    data=df,
    vcov="cluster",
    cluster_cols=["unit_id"],
    backend="polars"  # default, fastest
)
```

### Python (DuckDB)

```python
from leanfe import leanfe

# Memory-efficient, can handle data larger than RAM
result = leanfe(
    formula="outcome ~ treatment + controls | unit_id + time_id",
    data="large_data.parquet",  # read directly from file
    vcov="cluster",
    cluster_cols=["unit_id"],
    backend="duckdb"  # low memory usage
)
```

### R (Polars)

```r
library(leanfe)

# Fast in-memory computation (default)
result <- leanfe(
    formula = "outcome ~ treatment + controls | unit_id + time_id",
    data = df,
    vcov = "cluster",
    cluster_cols = c("unit_id"),
    backend = "polars"
)
```

### R (DuckDB)

```r
library(leanfe)

# Memory-efficient, can handle data larger than RAM
result <- leanfe(
    formula = "outcome ~ treatment + controls | unit_id + time_id",
    data = "large_data.parquet",
    vcov = "cluster",
    cluster_cols = c("unit_id"),
    backend = "duckdb"
)
```

:::

## Performance

**YOCO + sparse matrices** make leanfe extremely fast for **all standard error types** ‚Äî IID, HC1, and clustered. DuckDB uses far less memory and can process datasets larger than RAM.

::: {.callout-note}
## Live Benchmarks
All performance numbers are generated from live benchmarks on standardized synthetic data. See the benchmark pages for current results on your hardware.
:::

**Key characteristics:**

- **Polars**: Fastest execution, higher memory usage
- **DuckDB**: Slightly slower, minimal memory (can handle data larger than RAM)
- **YOCO compression**: Reduces data significantly for discrete regressors
- **Scales to 50M+ observations**: Tested on large datasets

[View IID/HC1 benchmarks ‚Üí](benchmarks/overview.qmd) | [Clustered SE benchmarks ‚Üí](benchmarks/cluster-se.qmd)

## Installation

::: {.panel-tabset}

### Python

```bash
pip install leanfe
```

Or install from source:

```bash
pip install git+https://github.com/diegogentilepassaro/leanfe.git#subdirectory=package/python
```

### R

```r
# Install from GitHub
remotes::install_github("diegogentilepassaro/leanfe", subdir = "package/r")
```

:::

## Ready to dive in?

::: {.grid}

::: {.g-col-12 .g-col-md-4}
### üìñ Tutorials
Step-by-step guides for common use cases: DiD, event studies, IV regression.

[Browse tutorials ‚Üí](tutorials/basic-usage.qmd)
:::

::: {.g-col-12 .g-col-md-4}
### üìö API Reference
Complete documentation of all functions and parameters.

[Python API](reference/python.qmd) | [R API](reference/r.qmd)
:::

::: {.g-col-12 .g-col-md-4}
### üî¨ Benchmarks
Reproducible performance comparisons with PyFixest and fixest.

[View benchmarks ‚Üí](benchmarks/overview.qmd)
:::

:::
